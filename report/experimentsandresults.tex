% !Tex root = main.tex
\newpage
\section{Experiments and Results}
\label{sec:ExperimentsandResults}
In order to test the previously described \ac{TAD} approach several experiments
were performed, to find the optimal model for both the \ac{SISR} and \ac{IC}
tasks, to show the impact of the L1 ball on the model's robustness against
perturbations as well as evincing the feasibility of applying the \ac{TAD}
method in the video domain.

\begin{figure}[!htbp]
	\centering
	\includegraphics[width=14cm]{figures/model_adaptions}
	\caption{Model and Training adaptions during experiments in comparison
  to the baseline model by \cite{TAID}.}
  \label{fig:model_adaptions}
\end{figure}

As shown in \myfigref{fig:model_adaptions} a bunch of adjustments to the
baseline model (by \cite{TAID}) were tried for analysing the coherence between
the model complexity and its reconstruction performance. Thereby very small
architectures (6 layers) as well as comparable large architectures
(19 layers) were tested (baseline model has 10 layers), spanning
from $375.926$ to $1.299.126$ parameters. Since the model already is quite
shallow the removal of each layer had an impact on the resulting performance,
therefore especially the number of \textit{Resblocks} (two convolutional layers
and ReLU) has a huge impact on the reconstruction accuracy. Next to adaptions
to the baseline architecture completly new architectures have been tested, such
as networks without any residual pass (so no Resblocks) but convolutional layers
with either constant or varying (first increasing then decreasing) number of
filters (up to 256) have been used.
\newline
Next to several architectures the baseline model was improved by advancing the
training procedure. Next to enhancing the loss function as discussed in
\mysecref{sec:Approach_LF} instead of a constant an linearly annealing learning
rate was used, starting at $4*10^{-4}$ and annealing by factor $\gamma = 0.25$
after $20$, $100$ and again after $200$ training epochs. Adam optimizer was used
with $\beta = (0.9, 0.999)$, $\epsilon_{ADAM} = 10^{-8}$, gradient clipping and
zero weight decay.
\newline
To guarantee comparability to other super-resolution and colorization paper
in the image domain the model was trained using the DIV2K training dataset
(\cite{DIV2K}), while validated on the SET5 (\cite{SET5}), SET14 (\cite{SET14}),
BSDS100 (\cite{BSDS100}), URBAN100 (\cite{URBAN100}) and VDIV2K (\cite{DIV2K})
dataset. For similar reason for the video domain the model was pretrained using
DIV2K, actually trained on video clips from CDVL Database (Ntiaspen) and
validated on the widely known Vid4 dataset (Calendar, Foliage, Walk, City).
For improving generalization capabilities of the model and avoid overfitting
the image training data were also augmented (rotated, mirrored).
\newline
Similiarly, as widely used in the field of image reconstruction as a performance
measurement the \ac{PSNR} will be used.
\newline
A complete list of the most important testing configurations and their results
as well as a list of architectures can be found in the appendix.

\subsection{Impact of L1 Ball}
\label{sec:Experiments_EPS_BALL}
As already seen in \mychapterref{sec:Approach} introducing an $\epsilon$-ball
to the loss term pervents the model from overfitting on the low-dimensional
image, $X_{SLR} = X_{GD}$ (i.e. trivial solution $g_\theta = 0$ in the
beginning of the training).\footnote{As discussed in \mychapterref{sec:Approach}
the training is splitted into two parts, first learning only the difference
between the guidance image and a more optimal representation and later
learning the low-dimensional representation independent from the guidance
image.} However, the main contribution of the $\epsilon$-ball consists in the
increasing robustness against perturbations of $X_{SLR}$, which are modeled
as white Gaussian noise with standard deviation $\sigma$ within this project.
While a model trained with $\epsilon = 0$ is highly vulnerable to perturbations,
dropping \ac{PSNR} by $42 \%$ by adding noise with $\sigma = 0.11$ ($X_{SLR} \in
[0,1]^n$), a model trained with $\epsilon = 10$ is more stable dropping only
about $10 \%$ in the same scenario (scale = 4, dataset = SET14).

\begin{figure}[!htbp]
	\centering
	\includegraphics[width=8cm]{figures/epsball_qualitative_comp}
	\caption{Qualitative comparison between the impact of perturbation on a
  model trained without and with $\epsilon$-ball (scale = 4, dataset = SET14).}
  \label{fig:epsball_qualitative_comp}
\end{figure}

In the following experiment the same model (AETAD)\footnote{An overview over
all model architectures can be found in the appendix.} was trained with different
radii of the $\epsilon$-ball. It turns out that the right choice of $\epsilon$
is a trade-off between the reconstruction performance and robustness aginst
perturbations, comp. \myfigref{fig:epsball_perturbation}.

\begin{figure}[!htbp]
	\centering
	\includegraphics[width=10cm]{figures/epsball_perturbation}
	\caption{Reconstruction performance over several values of $\epsilon$
  and $\sigma$ (scale = 4).}
  \label{fig:epsball_perturbation}
\end{figure}

Also an increasing
$\epsilon$ improves the convergence rate during training, as shown in
\myfigref{fig:epsball_loss}, the model otherwise first overfits to $X_{GD}$
and then eventually finds a more optimal trade-off between fitting the
low- and high-dimensional image (with increasing $\frac{\alpha}{\beta}$ ratio).
However, as \myfigref{fig:epsball_perturbation} the radius of the $\epsilon$-ball
around $X_{GD}$ cannot be choosen infinitely large, since the overall performance
worsens as the impact of the guidance image on the model convergence decreases
(e.g. $\epsilon = 100$ in \myfigref{fig:epsball_perturbation}).

\begin{figure}[!htbp]
	\centering
	\includegraphics[width=6cm]{figures/epsball_loss_1_set14}
  \includegraphics[width=6cm]{figures/epsball_loss_50_set14}
	\caption{Closeness between $X_{SLR}$ and guidance image (blue) and $X_{SHR}$
  and groudtruth image (orange) for different values of $\epsilon$ (left:
  $\epsilon = 1$, right $\epsilon = 50$).}
  \label{fig:epsball_loss}
\end{figure}

\mytableref{table:epsilonotherscales} displays the impact of models trained
with different values of $\epsilon$ on the reconstruction capabilities on
non-trained scales. In general the model overfits on a scale it is trained on,
however allowing to deviate from the guidance image by increasing $\epsilon$
amplifies the effect of overfitting the learnt transformation to a the scaling
factor the model is trained on. Hence, as shown below especially for large
deviations in scaling factor the accuracy worsens with increasing $\epsilon$.

\begin{table}[!htbp]
	\begin{center}
	\begin{tabular}{c|c|c|c|c}
	epsilon & x2 & x4 & x8 & x16 \\
	\hline
	0 & 8.446 & 24.406 & 8.555 & 18.938 \\
	20 & 6.244 & 22.188 & 6.492 & 17.308 \\
	50 & 6.771 & 22.459 & 6.925 & 16.992 \\
	100 & 10.901 & 23.784 & 11.870 & 13.225 \\
	\end{tabular}
	\caption{Impact of $\epsilon$ on performance on non-trained scales
	(trained scale = 4, dataset = SET14).}
	\label{table:epsilonotherscales}
	\end{center}
\end{table}

Overall the choice of $\epsilon$ depends very much on the application and its
external conditions that should be solved, e.g. whether perturbations are
probable for example during the storing, downloading etc. process.
In case only the performance without any disturbances matters, $\epsilon < 10$
is a good choice, as it fastens convergence of the model, prevents overfitting
on the guidance image but also does not affect the accuracy without any
disturbances much. For the further experiments a value $\epsilon = 1$ was used.
\newline
Although described for the \ac{SISR} problem here the described impact of
the $\epsilon$-ball is similar over all other problems, which omitted here
for the matter of compactness of this report.

\subsection{Single-Image Super-Resolution}
\label{sec:Experiments_SISR}
Next to improving the robustness of the \ac{TAD} model several improvements
were made on both the way of training as well as on the architecture itself.
\myfigref{fig:psnr_complexty_sisr} shows the correlation on both the SET5
and the SET14 dataset for different architectures which were trained using the
same parameters (learning parameters as described above, $\epsilon = 10$) for
the sake of a comparability.

\begin{figure}[!htbp]
	\centering
	\includegraphics[width=18cm]{figures/psnr_complexity_sisr}
	\caption{Model complexity vs reconstruction performance for \ac{SISR}
	problem (scale = 4, dataset = SET14 and SET5).}
  \label{fig:psnr_complexty_sisr}
\end{figure}

Several conclusion can be drawn from \myfigref{fig:psnr_complexty_sisr}, which
could be confirmed also for the other validation datasets used:

\begin{itemize}
\item The model \textit{no\_tad} is the baseline model which is trained to
only upscale based on the guidance image, i.e. the standard approach to solve
the \ac{SISR} problem. Although the reconstruction performance of the
\textit{no\_tad} model is worse than state-of-the-art methods (e.g. VDSR
\cite{AISRUVDCN} shown in \myfigref{fig:vdsr}), clearly the task-aware
downscaling approach could largely improve the performance, compared the equivalent
\textit{aetad} model which is trained using task aware downscaling. In fact
for similar performance more than about $25 \%$ of the model parameters can
be omitted, still resulting in a better accuracy (comparison \textit{no\_tad}
vs \textit{aetad\_small}).
\item The \textit{Resblocks} have a large impact on the models performance,
purely convolutional models with neither a skip connection nor a ReLU layer
(as occurring in \textit{Resblocks}), such as the models \textit{conv\_only} or
\textit{conv\_only\_very\_large}, have an overall worse reconstruction
performance with a similar number of parameters.
\item In a direct comparison the model \textit{aetad\_direct4} performs worse
than the iteratively scaling structured, but otherwise equivalent model
\textit{aetad}.
\item In both displayed validation datasets the reconstruction performance
stagnates with increasing number of parameters, as the difference in \ac{PSNR}
between the \textit{aetad\_large} and the \textit{aetad\_very\_large}
model does not improve much anymore.
\end{itemize}

While more complex architectures than the baseline (\textit{Kim et al.}-model)
do not gain a lot of accuracy, for less complex models with similar architecture
there is a large drop in accurcy. Therefore, the baseline architecture already
is very reasonable.

\myfigref{fig:sisr_different_scales} shows the \ac{PSNR} curves for a model
trained on a scaling factor of 2, while being validated on both of the scaling
factor 2 and 4.

\begin{figure}[!htbp]
	\centering
	\includegraphics[width=10cm]{figures/sisr_different_scales}
	\caption{\ac{PSNR} curve on SET5 validation dataset for different scales
	(trained scaling factor = 2).}
  \label{fig:sisr_different_scales}
\end{figure}

\begin{table}[!htbp]
	\begin{center}
	\begin{tabular}{c|c|c|c|c}
	model & x2 & x4 & x8 & x16 \\
	\hline
  \textit{no\_tad} & 7.457 & 27.204 & 7.459 & 19.488 \\
	\textit{aetad\_very\_small} & 8.527 & 28.334 & 7.780 & 18.799 \\
	\textit{aetad\_very\_large} & 5.882 & 29.617 & 5.928 & 18.673 \\
	\end{tabular}
	\caption{Comparison of the reconstruction performance on non-trained scales
	between task aware and non task aware trained models on SET14.}
	\label{table:sisrotherscales}
	\end{center}
\end{table}


\begin{table}[!htbp]
	\begin{center}
	\begin{tabular}{c|c|c|c|c}
	scale & dataset & PSNR (Kim et al.) & PSNR (\textit{aetad\_skip2})
	& PSNR (\textit{aetad\_very\_small}) \\
	\hline
  x4 & SET5 & 31.81 & 31.814 & 30.302 \\
	x4 & SET14 & 28.63 & 28.665 & 28.334 \\
	x4 & URBAN100 & 26.63 & 24.156 & 23.084 \\
	x4 & BSDS100 & 28.51 & 28.601 & 25.719 \\
	\end{tabular}
	\caption{Comparison of reconstruction accuracy between Kim et al. \cite{TAID},
	\textit{aetad\_skip2} and \textit{aetad\_very\_small}
	model for scaling factor 4 on several validation datasets. }
	\label{table:sisperformance}
	\end{center}
\end{table}

\subsection{Image Colorization}
\label{sec:Experiments_IC}


\begin{figure}[!htbp]
	\centering
	\includegraphics[width=18cm]{figures/psnr_complexity_ic}
	\caption{Model complexity vs reconstruction performance for \ac{IC}
	problem (dataset = SET14 and SET5).}
  \label{fig:psnr_complexity_ic}
\end{figure}

\begin{table}[!htbp]
	\begin{center}
	\begin{tabular}{c|c|c|c|c}
	scale & dataset & PSNR (Kim et al.)
	& PSNR (\textit{aetad\_color\_large}) & $\frac{\# params kim et al.}{\# params aetad\_color\_large}$  \\
	\hline
  x4 & SET5 & None & 34.416 \\
	x4 & SET14 & None & 31.262 \\
	x4 & URBAN100 & 33.68 & 33.604 \\
	x4 & BSDS100 & 36.14 & 36.786 \\
	\end{tabular}
	\caption{Comparison of reconstruction accuracy between Kim et al. \cite{TAID},
	\textit{aetad\_color\_large} model on several validation datasets. }
	\label{table:icperformance}
	\end{center}
\end{table}

\subsection{Video Super-Resolution}
\label{sec:Experiments_VSR}

\begin{table}[!htbp]
	\begin{center}
	\begin{tabular}{c|c|c|c|c}
	scale & dataset & \ac{SISR} model & non task aware SOFVSR
	& task aware SOFVSR \\
	\hline
  x4 & CALENDAR & 21.297 & 19.190 & 18.573 \\
	x4 & CITY & 25.332 & 24.677 & 24.191 \\
	\end{tabular}
	\caption{Comparison of reconstruction accuracy of \ac{SISR} model and
	the rebuild SOFVSR model without and with \ac{TAD}.}
	\label{table:vsrperformance}
	\end{center}
\end{table}


\begin{enumerate}
\item super-large scale for videos
\end{enumerate}

\subsection{Qualitative Improvements}
\label{sec:Experiments_QI}
As demonstrated above \ac{TAD} is able to improve the performance of
image reconstruction models quantitatively, but the \ac{TAD} approach also
improves the results in a qualitative manner, in sense of that images can be
restored that would be able to be restored from the trivially downscaled image,
in the following shown using the example of a \ac{IC} task.
\newline
Consider \myfigref{fig:gummibears} displaying objects with equivalent shape
but different colors (gummibears). While by using trivial downscaling methods
like averaging over the colors (grayscale) some color information are
unrecoverably lost, e.g. the yellow and orange gummibear looking nearly
equivalent in grayscale, a task aware approach learns to keep basic color
information despite of downscaling, figuratively speaking. Hence, even the color
of shapes which are (exactly) similar in grayscale can be restored.

\begin{figure}[!htbp]
	\centering
	\includegraphics[width=8cm]{figures/gummibears_GRY}
	\includegraphics[width=8cm]{figures/gummibears_COL}
	\includegraphics[width=8cm]{figures/gummibears_SCOLT_notad}
	\includegraphics[width=8cm]{figures/gummibears_SCOLT}
	\caption{Image colorization of similar shapes (from upper left to lower
	right: grayscale, groundtruth, colorized without \ac{TAD}, colorized with \ac{TAD})}
  \label{fig:gummibears}
\end{figure}

% Describe the evaluation you did in a way, such that an independent researcher can repeat it. Cover the following questions:
% \begin{itemize}
%  \item \textit{What is the experimental setup and methodology?} Describe the setting of the experiments and give all the parameters in detail which you have used. Give a detailed account of how the experiment was conducted.
%  \item \textit{What are your results?} In this section, a \emph{clear description} of the results is given. If you produced lots of data, include only representative data here and put all results into the appendix.
% \end{itemize}
